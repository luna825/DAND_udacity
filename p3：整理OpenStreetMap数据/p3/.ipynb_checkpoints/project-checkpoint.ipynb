{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Data Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Area\n",
    "\n",
    "\n",
    "[Las Vegas, Nevada, USA](https://mapzen.com/data/metro-extracts/metro/las-vegas_nevada)\n",
    "\n",
    "拉斯维加斯是美国的赌城，娱乐之都，早就听说过，也非常想去，所以做项目时就想为此地做一下。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、地图遇到的问题\n",
    "发现有以下问题：\n",
    " 1. **街道名称缩写、不正确；**\n",
    " 2. **不正确的邮政编码；**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入必要的库，生成原文件10%样本的文件sample.osm;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#导入必要的库\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import cerberus\n",
    "import schema\n",
    "import codecs\n",
    "import string\n",
    "import schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "OSM_FILE = \"las-vegas_nevada.osm\"  # Replace this with your osm file\n",
    "SAMPLE_FILE = \"sample.osm\"\n",
    "\n",
    "k = 10 # Parameter: take every k-th top level element\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\n",
    "\n",
    "    Reference:\n",
    "    http://stackoverflow.com/questions/3095434/inserting-newlines-in-xml-file-generated-via-xml-etree-elementtree-in-python\n",
    "    \"\"\"\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "with open(SAMPLE_FILE, 'wb') as output:\n",
    "    output.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write('<osm>\\n  ')\n",
    "\n",
    "    # Write every kth top level element\n",
    "    for i, element in enumerate(get_element(OSM_FILE)):\n",
    "        if i % k == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write('</osm>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 看数据中有多少标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bounds': 1,\n",
      " 'member': 4333,\n",
      " 'nd': 1241838,\n",
      " 'node': 1048101,\n",
      " 'osm': 1,\n",
      " 'relation': 556,\n",
      " 'tag': 489437,\n",
      " 'way': 112116}\n"
     ]
    }
   ],
   "source": [
    "file_name = 'las-vegas_nevada.osm'\n",
    "\n",
    "\n",
    "def count_tags(filename):\n",
    "    tags = {}\n",
    "    for _,elem in ET.iterparse(filename):\n",
    "        if elem.tag in tags:\n",
    "            tags[elem.tag] +=1\n",
    "        else:\n",
    "            tags[elem.tag] =1\n",
    "    return tags\n",
    "        \n",
    "def test():\n",
    "    tags = count_tags('las-vegas_nevada.osm')\n",
    "    pprint.pprint(tags)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 316935, 'lower_colon': 165174, 'other': 7327, 'problemchars': 1}\n"
     ]
    }
   ],
   "source": [
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\" \\?%#$@\\,\\.\\t\\r\\n]')\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        for tag in element.iter(\"tag\"):\n",
    "            if lower.search(tag.attrib['k']):\n",
    "                keys['lower'] +=1\n",
    "            elif lower_colon.search(tag.attrib['k']):\n",
    "                keys['lower_colon'] += 1\n",
    "            elif problemchars.search(tag.attrib['k']):\n",
    "                keys[\"problemchars\"] += 1\n",
    "            else :\n",
    "                keys[\"other\"] += 1\n",
    "    return keys\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "    return keys\n",
    "    \n",
    "keys = process_map(file_name)\n",
    "pprint.pprint(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们编写了两个函数key_type（）和process_map（），这两个函数使用正则表达式匹配来分离我们的键值。 \n",
    "我们将我们的数据集分为4组：lower，lower_colon，problemchars，other。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1、街道名称缩写、不正确\n",
    "一些街道名称被缩写，例如“Marco St”，更新为全拼；\n",
    "\n",
    "一些街道名称不正确，例如“S Maryland Parkway Suite A-5-262”，进行了更正；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先打印所有的街道名称，查看全部类型的街道名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': set(['Spanish Ridge Ave., Suite 1', 'West Gary Avenue #1']),\n",
      " '10': set(['S. Valley View Blvd. Ste 10']),\n",
      " '100': set(['S Eastern Ave #100']),\n",
      " '103': set(['South Pecos Road Suite 103']),\n",
      " '106': set(['S Grand Canyon Dr #106']),\n",
      " '107': set(['S Decatur Blvd #107']),\n",
      " '11': set(['Chandler Ave #11']),\n",
      " '110': set(['South Jones Boulevard Suite 110']),\n",
      " '111-559': set(['8465 W Sahara Avenue Suite 111-559']),\n",
      " '115': set(['North Hualapai Way #115']),\n",
      " '1170': set(['Fremont Street Ste. 1170']),\n",
      " '120': set(['E SILVERADO RANCH BLVD Suite 120', 'Silverado Ranch Blvd #120']),\n",
      " '15': set(['E Sahara Blvd #15']),\n",
      " '150': set(['West Horizon Ridge Parkway, STE 150']),\n",
      " '16': set(['Polaris Ave #16']),\n",
      " '170': set(['Sky Pointe Dr #170']),\n",
      " '207': set(['E Sahara Ave #207']),\n",
      " '275': set(['Camino Al Norte #275']),\n",
      " '2D': set(['Spring Mountain Rd #2D']),\n",
      " '3230': set(['W Sahara Ave #3230']),\n",
      " '500': set(['Howard Hughes Parkway, Suite 500']),\n",
      " '705': set(['West Ali Baba Lane #705']),\n",
      " '790': set(['Howard Hughes Pkwy #790']),\n",
      " '93': set(['Highway 93']),\n",
      " 'A': set(['E Tropicana Ave #A', 'West Post Road A']),\n",
      " 'A-5-262': set(['S Maryland Parkway Suite A-5-262']),\n",
      " 'AVE': set(['W PACIFIC AVE']),\n",
      " 'Alicante': set(['Via Alicante']),\n",
      " 'Apache': set(['S Fort Apache', 'S. Fort Apache']),\n",
      " 'Ave': set(['4760 S Polaris Ave',\n",
      "             'E Cheyenne Ave',\n",
      "             'E Sahara Ave',\n",
      "             'East Tropicana Ave',\n",
      "             'S Eastern Ave',\n",
      "             'S. Eastern Ave',\n",
      "             'W Cactus Ave',\n",
      "             'W Sahara Ave',\n",
      "             'W Twain Ave',\n",
      "             'W Washington Ave',\n",
      "             'W. Sahara Ave']),\n",
      " 'Ave.': set(['200 Hoover Ave.',\n",
      "              '6601 W. Twain Ave.',\n",
      "              'East Twain Ave.',\n",
      "              'Glendale Ave.',\n",
      "              'Hoover Ave.',\n",
      "              'W. Arby Ave.',\n",
      "              'West Sahara Ave.']),\n",
      " 'B': set(['Avenue B', 'West Sahara Avenue #B']),\n",
      " 'B12': set(['W Sahara Ave #B12']),\n",
      " 'Blvd': set(['Adams Blvd',\n",
      "              'Buchanan Blvd',\n",
      "              'Carmen Blvd',\n",
      "              'S Casino Center Blvd',\n",
      "              'S Rainbow Blvd',\n",
      "              'S Valley View Blvd',\n",
      "              'Thomas Ryan Blvd',\n",
      "              'W Charleston Blvd']),\n",
      " 'Blvd.': set(['E. Flamingo Blvd.',\n",
      "               'N. Las Vegas Blvd.',\n",
      "               'S Rainbow Blvd.',\n",
      "               'West Lake Mead Blvd.']),\n",
      " 'Bonneville': set(['Bonneville']),\n",
      " 'Boulevard': set(['Adams Boulevard',\n",
      "                   'Centennial Center Boulevard',\n",
      "                   'Decatur Boulevard',\n",
      "                   'Del Webb Boulevard',\n",
      "                   'E. Charleston Boulevard',\n",
      "                   'East Charleston Boulevard',\n",
      "                   'East Lake Mead Boulevard',\n",
      "                   'East Silverado Ranch Boulevard',\n",
      "                   'Lamb Boulevard',\n",
      "                   'Las Vegas Boulevard',\n",
      "                   'Montelago Boulevard',\n",
      "                   'N Casino Center Boulevard',\n",
      "                   'North Arroyo Grande Boulevard',\n",
      "                   'North Decatur Boulevard',\n",
      "                   'North Jones Boulevard',\n",
      "                   'North Lamb Boulevard',\n",
      "                   'North Las Vegas Boulevard',\n",
      "                   'North Nellis Boulevard',\n",
      "                   'North Rainbow Boulevard',\n",
      "                   'North Rampart Boulevard',\n",
      "                   'Nu Wav Kaiv Boulevard',\n",
      "                   'Rainbow Boulevard',\n",
      "                   'S Las Vegas Boulevard',\n",
      "                   'South Casino Center Boulevard',\n",
      "                   'South Decatur Boulevard',\n",
      "                   'South Hollywood Boulevard',\n",
      "                   'South Jones Boulevard',\n",
      "                   'South Las Vegas Boulevard',\n",
      "                   'South Martin L King Boulevard',\n",
      "                   'South Moapa Valley Boulevard',\n",
      "                   'South Nellis Boulevard',\n",
      "                   'South Rainbow Boulevard',\n",
      "                   'South Rampart Boulevard',\n",
      "                   'South Valley View Boulevard',\n",
      "                   'Sun City Boulevard',\n",
      "                   'Valley View Boulevard',\n",
      "                   'Wayne Newton Boulevard',\n",
      "                   'West Charleston Boulevard',\n",
      "                   'West Lake Mead Boulevard',\n",
      "                   'West Oakey Boulevard']),\n",
      " 'Buckskin': set(['W Buckskin']),\n",
      " 'Canto': set(['Via Bel Canto']),\n",
      " 'Charleston': set(['W Charleston']),\n",
      " 'Cir': set(['Sego Glen Cir']),\n",
      " 'Circle': set(['Citadel Circle',\n",
      "                'Inner Circle',\n",
      "                'Mall Ring Circle',\n",
      "                'Village Center Circle']),\n",
      " 'Dr': set(['Club House Dr',\n",
      "            'Corporate Park Dr',\n",
      "            'S Highland Dr',\n",
      "            'Village Walk Dr']),\n",
      " 'East': set(['Town Square East']),\n",
      " 'Experience': set(['Fremont Street Experience']),\n",
      " 'G': set(['Avenue G']),\n",
      " 'Highway': set(['Boulder Highway',\n",
      "                 'Nevada Highway',\n",
      "                 'North Boulder Highway',\n",
      "                 'South Boulder Highway',\n",
      "                 'Valley of Fire Highway']),\n",
      " 'Lavender': set(['W Lavender']),\n",
      " 'Ln': set(['Linda Ln']),\n",
      " 'Ln.': set(['Norman Rockwell Ln.']),\n",
      " 'M2': set(['W Craig Rd #M2']),\n",
      " 'Mt.': set(['Spring Mt.']),\n",
      " 'North': set(['Las Vegas Boulevard North']),\n",
      " 'Pkwy': set(['3547 S Maryland Pkwy', 'Grand Central Pkwy']),\n",
      " 'Prado': set(['Paseo del Prado']),\n",
      " 'Rd': set(['2560 E Sunset Rd',\n",
      "            'El Camino Rd',\n",
      "            'Hillpointe Rd',\n",
      "            'Losee Rd',\n",
      "            'Paradise Rd',\n",
      "            'S Fort Apache Rd',\n",
      "            'S Pecos Rd',\n",
      "            'W Craig Rd',\n",
      "            'W Warm Springs Rd']),\n",
      " 'Rd.': set(['E Sunset Rd.']),\n",
      " 'Rd5': set(['Airport Rd5']),\n",
      " 'S': set(['Las Vegas Blvd S',\n",
      "           'Las Vegas Boulevard S',\n",
      "           'Silverado Ranch Boulevard;Las Vegas Boulevard S']),\n",
      " 'S.': set(['Las Vegas Boulevard S.']),\n",
      " 'Sahara': set(['W Sahara']),\n",
      " 'South': set(['Las Vegas Blvd South',\n",
      "               'Las Vegas Boulevard South',\n",
      "               'Market Place South']),\n",
      " 'St': set(['Fremont St', 'Marco St', 'S 3rd St', 'S Main St']),\n",
      " 'St.': set(['5070 Arville St.']),\n",
      " 'Vegas': set(['Wynn Las Vegas']),\n",
      " 'Way': set(['6823 W. Ponderosa Way',\n",
      "             'Brandywine Way',\n",
      "             'Conestoga Way',\n",
      "             'Crystal Water Way',\n",
      "             'Donovan Way',\n",
      "             'Nevada Way',\n",
      "             'North Tenaya Way',\n",
      "             'SLS Way',\n",
      "             'Westminster Way',\n",
      "             'Wiesner Way']),\n",
      " 'apache': set(['South Fort apache']),\n",
      " 'ave': set(['W Sahara ave']),\n",
      " 'blvd': set(['N Rainbow blvd',\n",
      "              'S Las Vegas blvd',\n",
      "              'W Charleston blvd',\n",
      "              'W Lake Mead blvd']),\n",
      " 'blvd.': set(['S Las Vegas blvd.']),\n",
      " 'ln': set(['Rockwell ln'])}\n"
     ]
    }
   ],
   "source": [
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE) \n",
    "\n",
    "expected = [\"Avenue\", \"Commons\", \"Court\", \"Drive\", \"Lane\", \"Parkway\", \n",
    "                         \"Place\", \"Road\", \"Square\", \"Street\", \"Trail\"]\n",
    "\n",
    "\n",
    "def audit_street_type(street_types, street_name):     \n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name) \n",
    "\n",
    "\n",
    "def is_street_name(elem):         \n",
    "    return (elem.attrib['k'] == \"addr:street\") #Function to check value to be a street name \n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    return street_types\n",
    "\n",
    "sort_street_types = audit(file_name)\n",
    "pprint.pprint(dict(sort_street_types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据以上结果，修复街道名称缩写的问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建修正街道名称的字典\n",
    "mapping = { \"Ct\": \"Court\",\n",
    "            \"St\": \"Street\",\n",
    "            \"st\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"St,\": \"Street\",\n",
    "            \"ST\": \"Street\",\n",
    "            \"street\": \"Street\",\n",
    "            \"Street.\": \"Street\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Ave.\": \"Avenue\",\n",
    "            \"ave\": \"Avenue\",\n",
    "           \"AVE\":\"Avenue\",\n",
    "            \"Rd.\": \"Road\",   \n",
    "            \"rd.\": \"Road\",\n",
    "            \"Rd\": \"Road\",    \n",
    "            \"Hwy\": \"Highway\",\n",
    "            \"HIghway\": \"Highway\",\n",
    "            \"Pkwy\": \"Parkway\",\n",
    "            \"Pl\": \"Place\",      \n",
    "            \"place\": \"Place\",\n",
    "            \"Sedgwick\": \"Sedgwick Street\",\n",
    "            \"Sq.\": \"Square\",\n",
    "            \"Newbury\": \"Newbury Street\",\n",
    "           \"Cir\":\"Circle\",\n",
    "           \"S Maryland Parkway Suite A-5-262\":\"S Maryland Parkway\",\n",
    "           \"Spanish Ridge Ave., Suite 1\":\"Spanish Ridge Avenue\",\n",
    "           \"S Eastern Ave #100\":\"S Eastern Avenue\",\n",
    "           \"South Pecos Road Suite 103\":\"South Pecos Road\",\n",
    "           \"Chandler Ave #11\":\"Chandler Ave\",\n",
    "           }\n",
    "\n",
    "# 更正街道名称\n",
    "def update_name(name, mapping):    \n",
    "    for key in mapping:\n",
    "        if key in name:\n",
    "            name = string.replace(name,key,mapping[key])\n",
    "    return name\n",
    "    \n",
    "\n",
    "for street_type, ways in sort_street_types.iteritems():\n",
    "    for name in ways:\n",
    "        update_name(name, mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###  2、不正确的邮政编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'645': set(['6451112']),\n",
      " '890': set(['89002',\n",
      "             '89005',\n",
      "             '89011',\n",
      "             '89012',\n",
      "             '89014',\n",
      "             '89014-2132',\n",
      "             '89015',\n",
      "             '89019',\n",
      "             '89025',\n",
      "             '89030',\n",
      "             '89031',\n",
      "             '89040',\n",
      "             '89044',\n",
      "             '89052',\n",
      "             '89070',\n",
      "             '89074',\n",
      "             '89081',\n",
      "             '89086']),\n",
      " '891': set(['89101',\n",
      "             '89102',\n",
      "             '89102-4370',\n",
      "             '89103',\n",
      "             '89104',\n",
      "             '89104-1307',\n",
      "             '89105',\n",
      "             '89106',\n",
      "             '89107',\n",
      "             '89108',\n",
      "             '89108-7049',\n",
      "             '89109',\n",
      "             '89109-1907',\n",
      "             '89110',\n",
      "             '89113',\n",
      "             '89115',\n",
      "             '89117',\n",
      "             '89118',\n",
      "             '89119',\n",
      "             '89119-1001',\n",
      "             '89119-6304',\n",
      "             '89120',\n",
      "             '89121',\n",
      "             '89122',\n",
      "             '89123',\n",
      "             '89128',\n",
      "             '89128-6634',\n",
      "             '89129',\n",
      "             '89129-7260',\n",
      "             '89130',\n",
      "             '89131',\n",
      "             '89134',\n",
      "             '89135',\n",
      "             '89135-1020',\n",
      "             '89135-1038',\n",
      "             '89139',\n",
      "             '89142',\n",
      "             '89144',\n",
      "             '89145',\n",
      "             '89146',\n",
      "             '89146-2977',\n",
      "             '89147',\n",
      "             '89147-4111',\n",
      "             '89147-8491',\n",
      "             '89148',\n",
      "             '89149',\n",
      "             '89154',\n",
      "             '89156',\n",
      "             '89161',\n",
      "             '89166',\n",
      "             '89169',\n",
      "             '89178',\n",
      "             '89179',\n",
      "             '89183',\n",
      "             '89191']),\n",
      " '892': set(['8929']),\n",
      " 'NV ': set(['NV 89014',\n",
      "             'NV 89030',\n",
      "             'NV 89031',\n",
      "             'NV 89052',\n",
      "             'NV 89101',\n",
      "             'NV 89107',\n",
      "             'NV 89109',\n",
      "             'NV 89117',\n",
      "             'NV 89119',\n",
      "             'NV 89123',\n",
      "             'NV 89124',\n",
      "             'NV 89129',\n",
      "             'NV 89134',\n",
      "             'NV 89135',\n",
      "             'NV 89142',\n",
      "             'NV 89191']),\n",
      " 'Nev': set(['Nevada 89113'])}\n"
     ]
    }
   ],
   "source": [
    "def audit_zipcode(invalid_zipcodes, zipcode):\n",
    "    threeDigits = zipcode[0:3]\n",
    "    \n",
    "    if len(zipcode) != 6:                            \n",
    "        invalid_zipcodes[threeDigits].add(zipcode)    \n",
    "    elif not threeDigits.isdigit():                    \n",
    "        invalid_zipcodes[threeDigits].add(zipcode)\n",
    "    \n",
    "    elif threeDigits != '891':                       \n",
    "        invalid_zipcodes[threeDigits].add(zipcode)\n",
    "        \n",
    "def is_zipcode(elem):\n",
    "    return (elem.attrib['k'] == \"addr:postcode\")\n",
    "\n",
    "def audit_zip(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    invalid_zipcodes = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_zipcode(tag):\n",
    "                    audit_zipcode(invalid_zipcodes,tag.attrib['v'])\n",
    "    return invalid_zipcodes\n",
    "\n",
    "sort_zipcode = audit_zip(file_name)\n",
    "pprint.pprint(dict(sort_zipcode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def update_zip(zipcode):\n",
    "    if zipcode[0:3] == 'NV ':\n",
    "        zipcode = zipcode[3:]\n",
    "        return zipcode\n",
    "    elif zipcode[0:6] == 'Nevada':\n",
    "        zipcode = zipcode[7:]\n",
    "        return zipcode\n",
    "    elif zipcode[0:3] != '891':\n",
    "        zipcode = 'None'\n",
    "        return zipcode\n",
    "    elif zipcode[0:3] == '891' and len(zipcode) >6:\n",
    "         zipcode = zipcode[0:5]\n",
    "         return zipcode\n",
    " \n",
    "for street_type, ways in sort_zipcode.iteritems():\n",
    "    for name in ways:\n",
    "        if update_zip(name):\n",
    "            update_zip(name)\n",
    "            \n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们将清理文件并分隔数据;\n",
    "\n",
    "tags_clean 函数用来设置id,key,value和type的值，在把街道名称和邮编的更改添加到字典时使用；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OSM_PATH = file_name\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "SCHEMA = schema.Schema\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "\n",
    "def tags_clean(id , tag ):\n",
    "    node_tagss = {}\n",
    "    node_tagss['id'] = int(id)\n",
    "    if tag.attrib['k'] == \"addr:street\":\n",
    "        node_tagss['value'] = update_name(tag.attrib['v'], mapping)\n",
    "    elif tag.attrib['k'] == \"addr:postcode\":\n",
    "        node_tagss['value'] = update_zip(tag.attrib['v'])\n",
    "    else:\n",
    "        node_tagss['value'] = tag.attrib['v']\n",
    "\n",
    "    if \":\" not in tag.attrib['k']:\n",
    "        node_tagss['key'] = tag.attrib['k']\n",
    "        node_tagss['type'] = 'regular'\n",
    "        \n",
    "    else:\n",
    "        pcolon = tag.attrib['k'].index(\":\") + 1\n",
    "        node_tagss['key'] = tag.attrib['k'][pcolon:]\n",
    "        node_tagss['type'] = tag.attrib['k'][:pcolon - 1]\n",
    "        \n",
    "    \n",
    "    return node_tagss\n",
    "    \n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "    node_tagss = {}\n",
    "    # YOUR CODE HERE\n",
    "    if element.tag == 'node':\n",
    "        for node in NODE_FIELDS:\n",
    "            node_attribs[node] = element.attrib[node]\n",
    "        node_attribs['id']= int(node_attribs['id'])\n",
    "        node_attribs['uid']= int(node_attribs['uid'])\n",
    "        node_attribs['changeset']= int(node_attribs['changeset'])\n",
    "        \n",
    "        node_attribs['lon']= float(node_attribs['lon'])\n",
    "        node_attribs['lat']= float(node_attribs['lat'])\n",
    "  \n",
    "        for tag in element.iter(\"tag\"):\n",
    "            tag_clean ={}\n",
    "            if PROBLEMCHARS.search(tag.attrib['k']) == None:\n",
    "                node_tagss = tags_clean(node_attribs['id'] , tag )\n",
    "                tags.append(node_tagss)\n",
    "        \n",
    "            #tag_clean = clean(tag)\n",
    "            #if tag_clean:\n",
    "            #    tags.append(tag_clean)\n",
    "        if node_attribs:\n",
    "            return {'node': node_attribs, 'node_tags': tags}\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    elif element.tag == 'way':\n",
    "        for way in WAY_FIELDS:\n",
    "            way_attribs[way] = element.attrib[way]\n",
    "        \n",
    "        way_attribs['id']= int(way_attribs['id'])\n",
    "        way_attribs['uid']= int(way_attribs['uid'])\n",
    "        way_attribs['changeset']= int(way_attribs['changeset'])\n",
    "        for tag in element.iter(\"tag\"):\n",
    "            tag_clean ={}\n",
    "            if PROBLEMCHARS.search(tag.attrib['k']) == None:\n",
    "                node_tagss = tags_clean(way_attribs['id'] , tag )\n",
    "                tags.append(node_tagss)\n",
    "        \n",
    "            #tag_clean = clean(tag)\n",
    "            #if tag_clean:\n",
    "            #    tags.append(tag_clean)\n",
    "                \n",
    "        count =0\n",
    "        for nodes in element.iter(\"nd\"):\n",
    "            wnd = {}\n",
    "            wnd['id'] = int(way_attribs['id'])\n",
    "            wnd['node_id'] = int(nodes.attrib['ref'])\n",
    "            wnd['position'] = count\n",
    "            count += 1\n",
    "            \n",
    "            way_nodes.append(wnd)\n",
    "            \n",
    "        if way_attribs:\n",
    "            return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "        else:\n",
    "            return None\n",
    "            \n",
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_strings = (\n",
    "            \"{0}: {1}\".format(k, v if isinstance(v, str) else \", \".join(v))\n",
    "            for k, v in errors.iteritems()\n",
    "        )\n",
    "        raise cerberus.ValidationError(\n",
    "            message_string.format(field, \"\\n\".join(error_strings))\n",
    "        )\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "    # sample of the map when validating.\n",
    "    process_map(OSM_PATH, validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建las-vegas_nevada.db数据库，将各csv文件导入数据库中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、探索数据\n",
    "以下部分是对拉斯维加斯数据集的探索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文件大小\n",
    "\n",
    " * las-vegas_nevada.osm : 215 MB\n",
    " * las-vegas_nevada.db :120MB\n",
    " * nodes.csv : 84.2 MB\n",
    " * nodes_tags.csv : 2.28 MB\n",
    " * ways.csv : 6.46 MB\n",
    " * ways_nodes.csv : 29.7 MB\n",
    " * ways_tags.csv : 14.3 MB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### node节点数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlite> SELECT count(*)\n",
    "   ...> FROM nodes;\n",
    "1048101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 道路数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlite> SELECT count(*)\n",
    "   ...> FROM ways;\n",
    "112116"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用户（去重）数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlite> SELECT count(distinct(user.uid))\n",
    "   ...> FROM (SELECT uid\n",
    "   ...> FROM nodes\n",
    "   ...> UNION all\n",
    "   ...> SELECT uid\n",
    "   ...> FROM ways ) user;\n",
    "1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前10名贡献用户"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlite> SELECT user.user ,count(*)\n",
    "   ...> FROM ( SELECT user\n",
    "   ...> FROM nodes\n",
    "   ...> UNION all\n",
    "   ...> SELECT user\n",
    "   ...> FROM ways) user\n",
    "   ...> GROUP BY user.user\n",
    "   ...> ORDER BY count(*)\n",
    "   ...> DESC\n",
    "   ...> LIMIT 10 ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alimamo|251497\n",
    "tomthepom|121172\n",
    "woodpeck_fixbot|70826\n",
    "alecdhuse|66528\n",
    "abellao|55639\n",
    "gMitchellD|44635\n",
    "robgeb|41070\n",
    "nmixter|40093\n",
    "TheDutchMan13|39304\n",
    "Tom_Holland|33379"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 只提交过一次的用户数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlite> SELECT count(*)\n",
    "   ...> FROM\n",
    "   ...> (SELECT e.user, count(*)\n",
    "   ...> FROM ( SELECT user\n",
    "   ...> FROM nodes\n",
    "   ...> UNION all\n",
    "   ...> SELECT user\n",
    "   ...> FROM ways ) e\n",
    "   ...> GROUP BY e.user\n",
    "   ...> HAVING count(*)=1) ;\n",
    "244"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、其他数据探索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 十大便利设施"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlite> SELECT value, count(*)\n",
    "   ...> FROM  nodes_tags\n",
    "   ...> WHERE key ='amenity'\n",
    "   ...> GROUP BY value\n",
    "   ...> ORDER BY count(*) DESC\n",
    "   ...> LIMIT 10 ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restaurant|460\n",
    "place_of_worship|294\n",
    "fuel|282\n",
    "fast_food|267\n",
    "fountain|266\n",
    "school|208\n",
    "shelter|122\n",
    "toilets|85\n",
    "cafe|78\n",
    "bar|72\n",
    "\n",
    "翻译成汉语：\n",
    "餐馆| 460\n",
    "礼拜场所| 294\n",
    "燃料| 282\n",
    "快餐| 267\n",
    "喷泉|266\n",
    "学校|208\n",
    "住所|122\n",
    "厕所|85\n",
    "网吧|78\n",
    "酒吧|72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "果然在哪都是‘民以食为天’，餐馆第一，快餐第四；\n",
    "好奇心，究竟赌场等场所有多少？\n",
    "把上面的查询去掉限制前10，发现有：\n",
    "casino|10\n",
    "nightclub|10\n",
    "theatre|10\n",
    "cinema|8\n",
    "stripclub|3\n",
    "\n",
    "即：\n",
    "赌场|10\n",
    "牙医|10\n",
    "夜总会|10\n",
    "影院|10\n",
    "电影|8\n",
    "脱衣舞俱乐部|3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 十大美食"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlite> SELECT nodes_tags.value, count(*)\n",
    "   ...> FROM nodes_tags\n",
    "   ...> JOIN (SELECT DISTINCT(id) \n",
    "   ...> FROM nodes_tags\n",
    "   ...> WHERE value= 'restaurant') i\n",
    "   ...> ON nodes_tags.id = i.id\n",
    "   ...> WHERE nodes_tags.key = 'cuisine'\n",
    "   ...> GROUP BY nodes_tags.value\n",
    "   ...> ORDER BY count(*) DESC\n",
    "   ...> LIMIT 10;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mexican|41\n",
    "pizza|31\n",
    "american|20\n",
    "italian|16\n",
    "steak_house|16\n",
    "burger|14\n",
    "chinese|12\n",
    "japanese|9\n",
    "asian|8\n",
    "buffet|7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "墨西哥餐厅、披萨、美国餐厅占前三，此处墨西哥餐厅偏多；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、关于数据集的其他想法 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "改进或分析数据的额外建议，实施改进的益处及一些预期的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1.\n",
    "   * 建议：现在的地图数据是不完整的，看到很多用户只提交了一次，建议应该想办法增加用户的活跃度，使用用户激励手段，比如积分，贡献排行榜，游戏化任务，勋章，高贡献用户特权等；\n",
    "   * 好处：增加数据量，丰富地图数据；\n",
    "   * 问题：过程较为复杂，需要人员、资金充足；\n",
    "   \n",
    "\n",
    " 2.\n",
    "   * 建议：openstreetmap组织进行数据清洗和更新，可以官方组织工程师进行，也可以通过游戏化的方式发布由用户进行；\n",
    "   * 好处：数据会较为干净，用户使用更加精确；地图相关工作者使用地图时可以不用或者少量进行数据清洗，使用更高效；\n",
    "           \n",
    "   * 问题：需要资金，工程师团队，对于非盈利性组织来说，有很大难度；\n",
    "   \n",
    "\n",
    " 3.\n",
    "   * 建议：贡献量较少的用户较容易提供不规范的信息，我们可以先从贡献度少的用户开始清理；\n",
    "   * 好处：会提高数据的一致性和准确性；\n",
    "   * 问题：降低新用户的积极性；\n",
    "   \n",
    "  \n",
    " 4.\n",
    "   * 建议：数据的格式不统一，可以规范一下数据输入的格式；\n",
    "   * 好处：可以提高数据的规范性；\n",
    "   * 坏处：规则不够灵活，难以适应不同地区的情况；\n",
    "   \n",
    "   \n",
    " 5.\n",
    "   * 建议：由于本数据并不全面，我们可以通过外部的API，比如高德地图、谷歌地图、PokemonGo等，完善和校准本地图中的数据；\n",
    "   * 好处：可以填充信息，校准数据；\n",
    "   * 问题：数据可能重复度大，或者数据格式不同导入困难等\n",
    "      而且涉及商业合作，互为竞争对手，合作难度估计较大；"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
